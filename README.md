
-----

# üìö RAG Jur√≠dico H√≠brido (LanceDB & Sentence Transformers)

## ‚öñÔ∏è Descri√ß√£o do Projeto

Este projeto implementa um **Pipeline RAG (Retrieval-Augmented Generation) H√≠brido** especializado na indexa√ß√£o e recupera√ß√£o inteligente de informa√ß√µes a partir de **documentos legais** (leis, decretos, c√≥digos) e **conceitos jur√≠dicos b√°sicos**.

Ele combina as for√ßas da **Busca Vetorial (Semantic Search)** para entender o *sentido* da pergunta, e a **Busca Full-Text (BM25)** para garantir a precis√£o das palavras-chave, resultando em uma recupera√ß√£o de contexto (*retrieval*) altamente relevante para o dom√≠nio jur√≠dico.

### üéØ Casos de Uso

  * **Consultoria R√°pida:** Encontrar o artigo de lei ou conceito mais relevante para uma pergunta complexa.
  * **An√°lise de Processos:** Criar uma base de conhecimento para auxiliar na an√°lise e classifica√ß√£o de processos administrativos/tribut√°rios (conforme sugerido no bloco de c√≥digo de extens√£o).
  * **Educa√ß√£o Jur√≠dica:** Criar um "c√©rebro" de conceitos b√°sicos para garantir que a IA entenda a terminologia fundamental.

-----

## üõ†Ô∏è Tecnologias Principais

| Categoria | Tecnologia | Fun√ß√£o no Pipeline |
| :--- | :--- | :--- |
| **Banco de Dados** | **LanceDB v0.13** | Banco de dados vetorial de c√≥digo aberto, usado para armazenar os *chunks* de lei e seus *embeddings*, suportando busca h√≠brida (vetorial + FTS). |
| **Embeddings** | **`intfloat/multilingual-e5-large-instruct`** | Modelo de *embedding* de ponta, otimizado para v√°rios idiomas, superando modelos antigos em portugu√™s jur√≠dico para gerar vetores de alta qualidade. |
| **Processamento de Texto** | **`pdfplumber`** | Extra√ß√£o do texto dos documentos PDF carregados. |
| **Chunking** | **Regex (Fun√ß√£o `extrai_artigos_incisos`)** | M√©todo cir√∫rgico de segmenta√ß√£o de texto, focado em manter a integridade dos artigos, par√°grafos e incisos das leis. |
| **Busca H√≠brida** | **BM25 (Nat. no LanceDB & `rank_bm25`)** | Utilizado para a busca por palavras-chave (*full-text search*) e combina√ß√£o de *scores* na fun√ß√£o de consulta (`pergunta`). |
| **Reranking** | **N√£o especificado no c√≥digo** | O c√≥digo inclui uma etapa de `Reranking final (Cross-Encoder)`, mas a importa√ß√£o do `reranker` est√° faltando. √â a etapa final para refinar a ordem dos documentos recuperados. |

-----

## üöÄ Estrutura do Pipeline (C√©lulas)

### C√©lula 1: Instala√ß√£o e Setup

Instala as bibliotecas necess√°rias, dando √™nfase na instala√ß√£o for√ßada do `numpy` para evitar conflitos comuns no ambiente de *notebooks* e garantir compatibilidade.

### C√©lula 2: Upload, Conceitos e Modelo de Embeddings

1.  Permite o *upload* dos PDFs de leis (ex: CF, CTN, LAI, Lei 9.784).
2.  Define um conjunto de **mais de 70 conceitos jur√≠dicos b√°sicos** (IPTU, Taxa, Princ√≠pios) para enriquecer a base de conhecimento e garantir que o RAG tenha uma funda√ß√£o conceitual s√≥lida.
3.  Carrega o modelo de *embedding* `intfloat/multilingual-e5-large-instruct` na GPU (`device="cuda"`).

### C√©lula 3: Processamento, Chunking e Cria√ß√£o do LanceDB

Esta √© a etapa central:

1.  **Chunking Jur√≠dico:** A fun√ß√£o `extrai_artigos_incisos` utiliza *regex* para fatiar o texto, garantindo que cada *chunk* respeite a hierarquia normativa (Artigo, Par√°grafo, Inciso).
2.  **Gera√ß√£o de Metadados:** Extrai o nome da norma, o artigo, a fonte (nome do PDF) e classifica como `lei` ou `conceito`.
3.  **Vetoriza√ß√£o:** Gera os *embeddings* (vetores de 1024 dimens√µes) para todos os *chunks*.
4.  **LanceDB:** Cria a tabela `leis` no banco de dados **LanceDB 2.0** (`./lancedb_rag2`), armazena os dados vetoriais e metadados.
5.  **Indexa√ß√£o H√≠brida:** Cria √≠ndices vetoriais (`cosine` com **IVF\_PQ**) e um √≠ndice de busca *full-text* (**FTS/BM25**) para garantir uma recupera√ß√£o r√°pida e precisa de ambos os tipos.

### C√©lula 4: Fun√ß√£o de Busca H√≠brida e Reranking

A fun√ß√£o `pergunta` √© a interface de consulta e implementa a estrat√©gia de busca h√≠brida e reranking:

1.  **Busca Vetorial (k-NN):** Consulta inicial ao LanceDB para encontrar documentos semanticamente similares.
2.  **Refinamento com BM25:** Aplica a pontua√ß√£o BM25 para as palavras-chave na sub-amostra recuperada.
3.  **Combina√ß√£o de Scores:** Utiliza pesos ajust√°veis (`VETOR_WEIGHT=0.7`, `BM25_WEIGHT=0.3`) para criar um `score_hybrid`, balanceando similaridade sem√¢ntica e relev√¢ncia de palavras.
    $$\text{Score H√≠brido} = (\text{Vetor Weight} \times \text{Similaridade}) + (\text{BM25 Weight} \times \text{BM25 Score})$$
4.  **Reranking (Cross-Encoder):** (Falta a defini√ß√£o do modelo `reranker`). Um passo final para reordenar os resultados com base em uma an√°lise mais profunda da relev√¢ncia entre a pergunta e o documento.

-----

## üí° Pr√≥ximos Passos Sugeridos

O c√≥digo j√° sugere uma excelente evolu√ß√£o:

  * **Tabela `processos` no LanceDB:** Estender a funcionalidade para indexar e buscar resumos e metadados de processos administrativos/tribut√°rios (usando o tipo `pa.timestamp` para datas).
  * **Integra√ß√£o com LLM (Gera√ß√£o):** O c√≥digo atual foca no *Retrieval*. O pr√≥ximo passo √© integrar um LLM (ex: GPT-4, Llama 3) para que, ap√≥s recuperar os documentos relevantes, ele **gere a resposta** com base no contexto encontrado (RAG completo).
  * **Defini√ß√£o do Reranker:** Incluir o carregamento de um modelo `Cross-Encoder` otimizado para *reranking* (ex: `cross-encoder/ms-marco-TinyBERT-L-2-v2`).

-----

## ‚å®Ô∏è Como Executar

1.  Abra o arquivo (`.ipynb` ou `.py`) em um ambiente com suporte a GPU (ex: Google Colab).
2.  Execute as c√©lulas em ordem.
3.  Fa√ßa o *upload* dos PDFs de leis quando solicitado.
4.  Utilize a fun√ß√£o `pergunta()` para testar a busca:
    ```python
    pergunta("o que √© IPTU?")
    ```

-----
